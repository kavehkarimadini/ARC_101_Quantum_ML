{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97790305-5d93-4abc-a070-d587d7de7e68",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **ðŸ“„ Gaussian SchrÃ¶dinger Bridge â€” Cheat Sheet**\n",
    "\n",
    "---\n",
    "\n",
    "# **1. Optimal Transport (OT)**\n",
    "\n",
    "### **Static OT**\n",
    "\n",
    "Solve:\n",
    "$$\n",
    "\\min_\\pi \\int |x - x'|^2 , d\\pi\n",
    "$$\n",
    "subject to $\\pi$ coupling $\\rho_0, \\rho_1$.\n",
    "\n",
    "Only end-point movement; no time evolution.\n",
    "\n",
    "### **Dynamic OT (Benamouâ€“Brenier)**\n",
    "\n",
    "Solve:\n",
    "$$\n",
    "\\min_{\\rho_t,v_t} \\int_0^1 \\frac12 |v_t|^2 dt\n",
    "$$\n",
    "subject to:\n",
    "$$\n",
    "\\partial_t \\rho_t = -\\nabla \\cdot (\\rho_t v_t)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# **2. SchrÃ¶dinger Bridges (SBs)**\n",
    "\n",
    "Given reference process $Y_t$ with law $Q_t$:\n",
    "\n",
    "$$\n",
    "\\min_{P_0=\\nu, P_1=\\nu_1} \\mathrm{KL}(P_t ,|, Q_t)\n",
    "$$\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "> The **most likely stochastic evolution** between two distributions, closest to a given SDE.\n",
    "\n",
    "Connection:\n",
    "$$\n",
    "\\text{SB} = \\text{Dynamic OT} + \\text{Entropy regularization}\n",
    "$$\n",
    "\n",
    "Ïƒ â†’ 0 â‡’ classical OT.\n",
    "\n",
    "---\n",
    "\n",
    "# **3. Reference SDE**\n",
    "\n",
    "General linear reference:\n",
    "$$\n",
    "dY_t = (c_t Y_t + \\alpha_t),dt + g_t , dW_t\n",
    "$$\n",
    "\n",
    "Covers:\n",
    "\n",
    "* Brownian motion\n",
    "* OU\n",
    "* VP / VE / sub-VP\n",
    "* Brownian dynamics (BDT)\n",
    "* Many ML diffusions\n",
    "\n",
    "---\n",
    "\n",
    "# **4. Gaussian SchrÃ¶dinger Bridges (GSBs)**\n",
    "\n",
    "Endpoints:\n",
    "$$\n",
    "X_0 \\sim \\mathcal{N}(\\mu_0, \\Sigma_0),\\quad\n",
    "X_1 \\sim \\mathcal{N}(\\mu_1, \\Sigma_1)\n",
    "$$\n",
    "\n",
    "Reference SDE linear â‡’ the optimal bridge is **Gaussian at all times**:\n",
    "$$\n",
    "X_t \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)\n",
    "$$\n",
    "\n",
    "Goal: **explicit formulas** for $\\mu_t$, $\\Sigma_t$, and drift.\n",
    "\n",
    "---\n",
    "\n",
    "# **5. Geometry: Buresâ€“Wasserstein Metric**\n",
    "\n",
    "Covariances live on manifold $S_{++}^d$.\n",
    "\n",
    "Lyapunov operator:\n",
    "Solve $A\\Sigma + \\Sigma A = U$ â‡’ $A = L_\\Sigma[U]$.\n",
    "\n",
    "Metric:\n",
    "$$\n",
    "\\langle U, V\\rangle_\\Sigma\n",
    "= \\frac12 \\mathrm{tr}(L_\\Sigma[U],V)\n",
    "$$\n",
    "\n",
    "GSB = geodesic on this manifold + potential:\n",
    "$$\n",
    "U_\\sigma(\\Sigma) = -\\frac{\\sigma^2}{8}\\mathrm{tr}(\\Sigma^{-1})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# **6. Closed-Form Covariance Evolution (Example: ÏƒWâ‚œ)**\n",
    "\n",
    "Define:\n",
    "$$\n",
    "D_\\sigma = \\sqrt{4 \\Sigma^{1/2} \\Sigma_0 \\Sigma^{1/2} + \\sigma^4 I}\n",
    "$$\n",
    "$$\n",
    "C_\\sigma = \\frac12 (\\Sigma^{1/2} D_\\sigma \\Sigma^{-1/2} - \\sigma^2 I)\n",
    "$$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "\\Sigma_t\n",
    "= (1 - t)^2 \\Sigma\n",
    "$$\n",
    "* $t^2 \\Sigma_0$\n",
    "* $t(1 - t)(C_\\sigma + C_\\sigma^\\top + \\sigma^2 I)$\n",
    "\n",
    "\n",
    "Ïƒ â†’ 0 â‡’ Wasserstein geodesic.\n",
    "Ïƒ â†’ âˆž â‡’ entropy-dominated smoothing.\n",
    "\n",
    "---\n",
    "\n",
    "# **7. Closed-Form Mean Evolution**\n",
    "\n",
    "General formula:\n",
    "$$\n",
    "\\mu_t = \\bar r_t \\mu_0 + r_t \\mu_1 + \\zeta(t) - r_t \\zeta(1)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $r_t, \\bar r_t$ depend on $c_t$ (reference SDE dynamics)\n",
    "* $\\zeta(t)$ depends on drift $\\alpha_t$\n",
    "\n",
    "If $\\alpha_t = 0$:\n",
    "$$\n",
    "\\mu_t = \\bar r_t \\mu_0 + r_t \\mu_1\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# **8. Full Closed-Form Drift (Theorem 3)**\n",
    "\n",
    "GSB satisfies SDE:\n",
    "$$\n",
    "dX_t = f_N(t,x), dt + g_t, dW_t\n",
    "$$\n",
    "\n",
    "### **Drift:**\n",
    "\n",
    "$$\n",
    "f_N(t,x)\n",
    "= S_t^\\top \\Sigma_t^{-1}(x - \\mu_t) + \\dot{\\mu}_t\n",
    "$$\n",
    "\n",
    "Where $S_t$ is explicitly:\n",
    "$$\n",
    "S_t = P_t - Q_t^\\top + (c_t \\kappa(t,t)(1-\\rho_t) - g_t^2 \\rho_t) I\n",
    "$$\n",
    "with all terms from reference SDE.\n",
    "\n",
    "**Important:**\n",
    "$$\n",
    "S_t^\\top \\Sigma_t^{-1} \\text{ is symmetric (proven)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# **9. Conditional Distributions (Corollary 1)**\n",
    "\n",
    "$$\n",
    "X_t \\mid X_0=x_0 \\sim \\mathcal{N}(\\mu_{t|0}, \\Sigma_{t|0})\n",
    "$$\n",
    "\n",
    "Both mean and covariance have closed forms.\n",
    "Similarly for $X_t \\mid X_1$.\n",
    "\n",
    "Used for:\n",
    "\n",
    "* Forward & backward SB sampling\n",
    "* Training GSBFLOW\n",
    "* Exact data pair generation\n",
    "\n",
    "---\n",
    "\n",
    "# **10. Examples (Table 1)**\n",
    "\n",
    "Plugging different (c_t,\\alpha_t,g_t) yields GSBs for:\n",
    "\n",
    "* **VE (variance-exploding)**\n",
    "* **VP (variance-preserving)**\n",
    "* **sub-VP**\n",
    "* **OU**\n",
    "* **BDT**\n",
    "* **Brownian motion**\n",
    "\n",
    "One unified formula â†’ many diffusion models.\n",
    "\n",
    "---\n",
    "\n",
    "# **11. GSBFLOW Algorithm**\n",
    "\n",
    "GSBFLOW trains a neural drift model $f_\\theta(t,x)$ by **matching**:\n",
    "\n",
    "$$\n",
    "f_\\theta(t,X_t) \\approx f_N(t,X_t)\n",
    "$$\n",
    "\n",
    "using **exact closed-form targets**, not noisy score estimates.\n",
    "\n",
    "Training pairs:\n",
    "$$\n",
    "(X_t,;f_N(t,X_t))\n",
    "$$\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* No backward SDE needed\n",
    "* No score matching / denoising objective\n",
    "* Stable gradients\n",
    "* Strong empirical performance\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a348144-f031-4846-8f85-f35a90c713d7",
   "metadata": {},
   "source": [
    "Trains a GSBFLOW-style model on MNIST\n",
    "\n",
    "Uses a Brownian bridge SchrÃ¶dinger bridge between:\n",
    "\n",
    "prior: Gaussian noise\n",
    "\n",
    "data: MNIST images\n",
    "\n",
    "Trains a CNN drift network by drift matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e0962-94b3-46e2-ac11-7943a2f02452",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **ðŸ““ GSBFLOW-Style MNIST Training â€” Walkthrough**\n",
    "\n",
    "---\n",
    "\n",
    "# **0. Setup**\n",
    "\n",
    "```python\n",
    "!pip install torch torchvision --quiet\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# **1. Imports & Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d74d135-4e71-4634-a06f-a5230e07f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c56125-fcee-4354-adf2-b025e86885b1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **2. Load MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec5f075-38d2-4ca0-8de9-90243bbe6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "BATCH_SIZE = 128       # number of images per batch\n",
    "NUM_EPOCHS = 5         # number of passes over the training data (increase for better results)\n",
    "LR = 2e-4              # learning rate for optimizer\n",
    "SIGMA = 0.5            # Brownian noise scale for the bridge\n",
    "NUM_TRAIN_STEPS = None # if not None, you can limit total training steps (debugging)\n",
    "\n",
    "# Sampling hyperparameters (for generating images after training)\n",
    "NUM_SAMPLES = 16       # how many images to sample\n",
    "NUM_STEPS_SAMPLE = 50  # number of Euler steps for solving the ODE during sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f98dd402-1222-4ae3-96e5-5d24d928afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data_mnist\"\n",
    "# =====================================\n",
    "# 2. DATASET AND PREPROCESSING SECTION\n",
    "# =====================================\n",
    "\n",
    "def get_mnist_dataloader(batch_size: int) -> DataLoader:\n",
    "    \"\"\"\n",
    "    Create a PyTorch DataLoader for MNIST with simple preprocessing.\n",
    "    \"\"\"\n",
    "    # Compose a list of transformations applied to each MNIST image:\n",
    "    # 1. Convert PIL image to tensor (C x H x W, values in [0, 1])\n",
    "    # 2. Normalize to approximately [-1, 1] (common for generative models)\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),                      # convert image to tensor\n",
    "        T.Normalize((0.5,), (0.5,)),       # scale from [0,1] -> roughly [-1,1]\n",
    "    ])\n",
    "\n",
    "    # Download / load MNIST training set\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=DATA_DIR,       # directory to store data\n",
    "        train=True,          # use training split\n",
    "        download=True,       # if data not present, download it\n",
    "        transform=transform  # apply transformation defined above\n",
    "    )\n",
    "\n",
    "    # Wrap dataset in a DataLoader to handle batching and shuffling\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,           # dataset to load from\n",
    "        batch_size=batch_size,   # how many samples per batch\n",
    "        shuffle=True,            # shuffle data every epoch\n",
    "        num_workers=4,           # worker processes for loading data\n",
    "        pin_memory=True          # speed: pin memory (good when using GPU)\n",
    "    )\n",
    "\n",
    "    # Return the DataLoader object\n",
    "    return train_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a8c53-dfa4-409b-965f-3a2b4d9a0f0e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **3. Time Embedding Module**\n",
    "\n",
    "This embeds the scalar time $t\\in[0,1]$ into a vector the network can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b0ebec6-a2a6-4a16-b757-deca612c2775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. DRIFT NETWORK ARCHITECTURE\n",
    "# ================================\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple time embedding: embed scalar t into a higher-dimensional vector\n",
    "    using sinusoidal embeddings (like in transformers / diffusion models).\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int):\n",
    "        # Call parent constructor\n",
    "        super().__init__()\n",
    "        # Store the embedding dimension\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          t: shape (batch,) with values in [0,1]\n",
    "        Output:\n",
    "          embedding: shape (batch, dim)\n",
    "        \"\"\"\n",
    "        # Compute half dimension (we'll use sin and cos pairs)\n",
    "        half_dim = self.dim // 2\n",
    "        # Create frequency exponents linearly spaced\n",
    "        # (using float dtype and device same as t)\n",
    "        freqs = torch.linspace(0, half_dim - 1, half_dim, device=t.device)\n",
    "        # Scale frequencies so they span multiple periods\n",
    "        freqs = math.log(10000.0) * freqs / (half_dim - 1)\n",
    "        # Compute exponentials of frequencies\n",
    "        freqs = torch.exp(freqs)  # shape (half_dim,)\n",
    "\n",
    "        # Reshape t to (batch, 1) to broadcast with freqs\n",
    "        t = t.unsqueeze(1)  # (batch, 1)\n",
    "\n",
    "        # Compute argument of sin/cos: shape (batch, half_dim)\n",
    "        args = t * freqs\n",
    "\n",
    "        # Compute sin and cos embeddings\n",
    "        sin_emb = torch.sin(args)\n",
    "        cos_emb = torch.cos(args)\n",
    "\n",
    "        # Concatenate sin and cos along feature dimension -> (batch, dim)\n",
    "        emb = torch.cat([sin_emb, cos_emb], dim=1)\n",
    "\n",
    "        # Return final embedding\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb2c4a7-691b-49df-93e2-73d8bb85a661",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **4. Simple U-Net Drift Network**\n",
    "\n",
    "This predicts the drift $ f_\\theta(t, x_t) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "149162ed-657b-48f9-85a6-0d799a024374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A very simple U-Net-like convolutional network that predicts\n",
    "    the drift f_theta(t, x) given:\n",
    "      - current image x_t (noisy / interpolated)\n",
    "      - scalar time t\n",
    "    The network outputs a tensor with same shape as x_t (drift vector field).\n",
    "    \"\"\"\n",
    "    def __init__(self, time_dim: int = 128):\n",
    "        # Call parent constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # Store time embedding dimension\n",
    "        self.time_dim = time_dim\n",
    "\n",
    "        # Create time embedding module\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            TimeEmbedding(time_dim),       # sinusoidal time embedding\n",
    "            nn.Linear(time_dim, time_dim), # linear layer\n",
    "            nn.SiLU(),                    # nonlinearity\n",
    "        )\n",
    "\n",
    "        # Number of input channels for MNIST images (1 grayscale)\n",
    "        in_channels = 1\n",
    "\n",
    "        # Define the first convolution block (downsampling)\n",
    "        self.conv_down1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),  # conv 1\n",
    "            nn.GroupNorm(4, 32),                                   # normalize\n",
    "            nn.SiLU(),                                             # nonlinearity\n",
    "        )\n",
    "\n",
    "        # Second convolution block (downsampling)\n",
    "        self.conv_down2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # conv with stride=2 halves resolution\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        # Third convolution block (more features, same spatial size)\n",
    "        self.conv_mid = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        # Time embedding projection to match mid-channel dimension\n",
    "        self.time_to_mid = nn.Linear(time_dim, 64)\n",
    "\n",
    "        # Upsampling layer to recover original spatial resolution\n",
    "        self.upsample = nn.ConvTranspose2d(\n",
    "            64, 32, kernel_size=4, stride=2, padding=1\n",
    "        )\n",
    "\n",
    "        # Final convolution block to map back to 1 channel\n",
    "        self.conv_out = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(4, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the drift network.\n",
    "        Inputs:\n",
    "          x: (batch, 1, 28, 28) current image state X_t\n",
    "          t: (batch,) times in [0,1]\n",
    "        Output:\n",
    "          drift: (batch, 1, 28, 28)\n",
    "        \"\"\"\n",
    "        # Pass t through time MLP to get time embedding (batch, time_dim)\n",
    "        t_emb = self.time_mlp(t)  # (B, time_dim)\n",
    "\n",
    "        # First conv block (no stride) -> keep 28x28 size, increase channels to 32\n",
    "        h1 = self.conv_down1(x)  # (B, 32, 28, 28)\n",
    "\n",
    "        # Second conv block with stride 2 -> 14x14, 64 channels\n",
    "        h2 = self.conv_down2(h1)  # (B, 64, 14, 14)\n",
    "\n",
    "        # Broadcast time embedding to spatial feature map:\n",
    "        # First project time embedding to 64 channels\n",
    "        t_mid = self.time_to_mid(t_emb)  # (B, 64)\n",
    "        # Reshape to (B, 64, 1, 1) so it can be added to feature map\n",
    "        t_mid = t_mid[:, :, None, None]  # (B, 64, 1, 1)\n",
    "\n",
    "        # Add time conditioning to middle feature map (broadcast over H,W)\n",
    "        h_mid = self.conv_mid(h2 + t_mid)  # (B, 64, 14, 14)\n",
    "\n",
    "        # Upsample back to 28x28 and reduce channels to 32\n",
    "        h_up = self.upsample(h_mid)  # (B, 32, 28, 28)\n",
    "\n",
    "        # Final conv block to get output drift of shape (B, 1, 28, 28)\n",
    "        out = self.conv_out(h_up)  # (B, 1, 28, 28)\n",
    "\n",
    "        # Return predicted drift\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f900a35-278d-423e-b7f5-f0f949bac1d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **5. Brownian Bridge SchrÃ¶dinger Bridge**\n",
    "\n",
    "This is the analytic SB between two points $x_0 \\to x_1$:\n",
    "\n",
    "$$\n",
    "X_t = (1-t)x_0 + t x_1 + \\sigma\\sqrt{t(1-t)},\\epsilon\n",
    "$$\n",
    "\n",
    "The drift is:\n",
    "\n",
    "$$\n",
    "f^*(t, x_t) = \\frac{x_1 - x_t}{1 - t}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b944e789-2157-455a-9233-56c747812dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 4. BROWNIAN BRIDGE SCHRÃ–DINGER BRIDGE\n",
    "# =========================================\n",
    "\n",
    "def sample_brownian_bridge(\n",
    "    x0: torch.Tensor,\n",
    "    x1: torch.Tensor,\n",
    "    t: torch.Tensor,\n",
    "    sigma: float\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Sample a Brownian bridge state X_t between x0 and x1.\n",
    "\n",
    "    Brownian bridge between two points (x0, x1) over [0,1] has:\n",
    "      E[X_t] = (1 - t) * x0 + t * x1\n",
    "      Var[X_t] = sigma^2 * t * (1 - t)\n",
    "\n",
    "    We sample:\n",
    "      X_t = (1 - t) * x0 + t * x1 + sigma * sqrt(t(1-t)) * eps\n",
    "\n",
    "    We also return the *exact* conditional drift:\n",
    "      f*(t, x_t | x1) = (x1 - x_t) / (1 - t)\n",
    "    which is the drift of a Brownian bridge SDE:\n",
    "      dX_t = (x1 - X_t) / (1 - t) dt + sigma dW_t\n",
    "\n",
    "    Inputs:\n",
    "      x0: (B, C, H, W) starting noise\n",
    "      x1: (B, C, H, W) target data\n",
    "      t:  (B,) times\n",
    "      sigma: noise scale\n",
    "\n",
    "    Outputs:\n",
    "      x_t:        (B, C, H, W) sampled intermediate state\n",
    "      drift_star: (B, C, H, W) analytic SB drift at (t, x_t)\n",
    "    \"\"\"\n",
    "    # Ensure t has shape (B, 1, 1, 1) for broadcasting over image dimensions\n",
    "    t_img = t.view(-1, 1, 1, 1)  # (B,1,1,1)\n",
    "\n",
    "    # Compute deterministic mean part of Brownian bridge at time t:\n",
    "    # (1 - t) * x0 + t * x1\n",
    "    mean_t = (1.0 - t_img) * x0 + t_img * x1\n",
    "\n",
    "    # Compute standard deviation for Brownian bridge at time t:\n",
    "    # std = sigma * sqrt(t * (1 - t))\n",
    "    std_t = sigma * torch.sqrt(torch.clamp(t * (1.0 - t), min=1e-5))  # (B,)\n",
    "    # Reshape std_t for broadcasting\n",
    "    std_img = std_t.view(-1, 1, 1, 1)  # (B,1,1,1)\n",
    "\n",
    "    # Sample standard normal noise with same shape as x0\n",
    "    eps = torch.randn_like(x0)  # (B,C,H,W)\n",
    "\n",
    "    # Sample X_t = mean_t + std_img * eps\n",
    "    x_t = mean_t + std_img * eps  # (B,C,H,W)\n",
    "\n",
    "    # Compute analytic Brownian bridge drift:\n",
    "    # f*(t,x_t) = (x1 - x_t) / (1 - t)\n",
    "    # Avoid division by 0 by adding a small epsilon\n",
    "    eps_denom = 1e-5\n",
    "    denom = (1.0 - t_img) + eps_denom  # (B,1,1,1)\n",
    "    drift_star = (x1 - x_t) / denom  # (B,C,H,W)\n",
    "\n",
    "    # Return sampled state and analytic drift\n",
    "    return x_t, drift_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad2758-9ae4-43a1-b7a3-79b30015bd29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **6. Training Loop (GSBFLOW-Style Drift Matching)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eddde9ae-b65e-4555-8929-c54e120ec8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 5. TRAINING LOOP FOR GSBFLOW-STYLE\n",
    "# =====================================\n",
    "\n",
    "def train_gsbflow_mnist():\n",
    "    \"\"\"\n",
    "    Main training function for the GSBFLOW-style Brownian bridge model on MNIST.\n",
    "    \"\"\"\n",
    "    # Get MNIST training DataLoader\n",
    "    train_loader = get_mnist_dataloader(BATCH_SIZE)\n",
    "\n",
    "    # Create an instance of the drift network and move it to the chosen device\n",
    "    model = SimpleUNet(time_dim=128).to(device)\n",
    "\n",
    "    # Use Adam optimizer to train model parameters\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    # Put model in training mode (enables e.g., dropout, batchnorm updates)\n",
    "    model.train()\n",
    "\n",
    "    # Initialize global step counter (for optional stopping condition)\n",
    "    global_step = 0\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Loop over batches from the DataLoader\n",
    "        for batch_idx, (x1, _) in enumerate(train_loader):\n",
    "            # Move batch of images to the device (GPU/CPU)\n",
    "            x1 = x1.to(device)  # (B,1,28,28)\n",
    "\n",
    "            # Get batch size (may be smaller on last batch)\n",
    "            B = x1.size(0)\n",
    "\n",
    "            # Sample Gaussian noise x0 as starting distribution\n",
    "            # Same shape as x1, from N(0, I)\n",
    "            x0 = torch.randn_like(x1)  # (B,1,28,28)\n",
    "\n",
    "            # Sample times t uniformly in (0,1)\n",
    "            # Shape: (B,)\n",
    "            t = torch.rand(B, device=device)\n",
    "\n",
    "            # Sample Brownian bridge state X_t and analytic drift at that state\n",
    "            x_t, drift_star = sample_brownian_bridge(\n",
    "                x0=x0, x1=x1, t=t, sigma=SIGMA\n",
    "            )\n",
    "\n",
    "            # Predict drift using our neural network model\n",
    "            # model expects x_t and t as inputs\n",
    "            drift_pred = model(x_t, t)  # (B,1,28,28)\n",
    "\n",
    "            # Compute mean-squared error between predicted drift and analytic drift\n",
    "            loss = F.mse_loss(drift_pred, drift_star)\n",
    "\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagate gradients from loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Take an optimization step to update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Increase global step counter\n",
    "            global_step += 1\n",
    "\n",
    "            # Optionally, print training progress every N steps\n",
    "            if global_step % 100 == 0:\n",
    "                print(\n",
    "                    f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n",
    "                    f\"Batch [{batch_idx+1}/{len(train_loader)}] \"\n",
    "                    f\"Step {global_step} \"\n",
    "                    f\"Loss: {loss.item():.4f}\"\n",
    "                )\n",
    "\n",
    "            # Optional: allow early stopping after some number of steps (debug)\n",
    "            if NUM_TRAIN_STEPS is not None and global_step >= NUM_TRAIN_STEPS:\n",
    "                break\n",
    "\n",
    "        # If early stopping condition triggered, break outer epoch loop\n",
    "        if NUM_TRAIN_STEPS is not None and global_step >= NUM_TRAIN_STEPS:\n",
    "            break\n",
    "\n",
    "    # After training completes, return the trained model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0b28f69-41ac-48a5-87c7-c357b6390d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Batch [100/469] Step 100 Loss: 2.7460\n",
      "Epoch [1/5] Batch [200/469] Step 200 Loss: 1.3131\n",
      "Epoch [1/5] Batch [300/469] Step 300 Loss: 3.3786\n",
      "Epoch [1/5] Batch [400/469] Step 400 Loss: 0.6795\n",
      "Epoch [2/5] Batch [31/469] Step 500 Loss: 0.5843\n",
      "Epoch [2/5] Batch [131/469] Step 600 Loss: 0.5745\n",
      "Epoch [2/5] Batch [231/469] Step 700 Loss: 0.6986\n",
      "Epoch [2/5] Batch [331/469] Step 800 Loss: 0.6274\n",
      "Epoch [2/5] Batch [431/469] Step 900 Loss: 0.5580\n",
      "Epoch [3/5] Batch [62/469] Step 1000 Loss: 0.8079\n",
      "Epoch [3/5] Batch [162/469] Step 1100 Loss: 0.8380\n",
      "Epoch [3/5] Batch [262/469] Step 1200 Loss: 0.6169\n",
      "Epoch [3/5] Batch [362/469] Step 1300 Loss: 0.5342\n",
      "Epoch [3/5] Batch [462/469] Step 1400 Loss: 0.6541\n",
      "Epoch [4/5] Batch [93/469] Step 1500 Loss: 0.7985\n",
      "Epoch [4/5] Batch [193/469] Step 1600 Loss: 0.5385\n",
      "Epoch [4/5] Batch [293/469] Step 1700 Loss: 0.9203\n",
      "Epoch [4/5] Batch [393/469] Step 1800 Loss: 0.6311\n",
      "Epoch [5/5] Batch [24/469] Step 1900 Loss: 0.6272\n",
      "Epoch [5/5] Batch [124/469] Step 2000 Loss: 0.6999\n",
      "Epoch [5/5] Batch [224/469] Step 2100 Loss: 14.7732\n",
      "Epoch [5/5] Batch [324/469] Step 2200 Loss: 0.5326\n",
      "Epoch [5/5] Batch [424/469] Step 2300 Loss: 1.8879\n"
     ]
    }
   ],
   "source": [
    "# Train the GSBFLOW-style Brownian bridge model on MNIST\n",
    "model = train_gsbflow_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00f4b3-72d5-4ccc-b2f6-00e2ecc8fb63",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **7. Sampling from the Trained Model**\n",
    "\n",
    "We integrate the learned ODE:\n",
    "\n",
    "$$\n",
    "dX_t = f_\\theta(t, X_t),dt.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f395e0b2-19ff-4065-bc56-7dd94a25460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 6. SAMPLING / GENERATION FROM MODEL\n",
    "# ======================================\n",
    "\n",
    "@torch.no_grad()  # disable gradient computation in sampling\n",
    "def sample_from_model(\n",
    "    model: nn.Module,\n",
    "    num_samples: int = NUM_SAMPLES,\n",
    "    num_steps: int = NUM_STEPS_SAMPLE,\n",
    "    sigma: float = SIGMA\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Sample images from the trained GSBFLOW-style model by solving\n",
    "    the forward ODE:\n",
    "      dX_t = f_theta(t, X_t) dt\n",
    "\n",
    "    We ignore Brownian noise in sampling for simplicity (deterministic flow).\n",
    "    This is common: flow-matching often uses an ODE for sampling.\n",
    "\n",
    "    Inputs:\n",
    "      model: trained drift network\n",
    "      num_samples: how many images to generate\n",
    "      num_steps: number of Euler steps used in integration\n",
    "      sigma: (unused here; kept for extension / reference)\n",
    "\n",
    "    Output:\n",
    "      samples: (num_samples,1,28,28) tensor of generated images in [-1,1]\n",
    "    \"\"\"\n",
    "    # Put model in eval mode (disables dropout, etc.)\n",
    "    model.eval()\n",
    "\n",
    "    # Start from standard Gaussian noise as initial samples X_0\n",
    "    x = torch.randn(num_samples, 1, 28, 28, device=device)\n",
    "\n",
    "    # Create time grid for [0,1]\n",
    "    # linspace from 0 to 1, inclusive\n",
    "    t_grid = torch.linspace(0.0, 1.0, num_steps + 1, device=device)\n",
    "\n",
    "    # Compute step size (delta t) assuming uniform steps\n",
    "    dt = t_grid[1] - t_grid[0]\n",
    "\n",
    "    # Loop over time steps from t_0 to t_{num_steps-1}\n",
    "    for i in range(num_steps):\n",
    "        # Current time t_i (scalar)\n",
    "        t = t_grid[i]  # scalar tensor\n",
    "\n",
    "        # Expand time to shape (batch,) for model input\n",
    "        t_batch = torch.full((num_samples,), t.item(), device=device)\n",
    "\n",
    "        # Predict drift at current state and time\n",
    "        drift = model(x, t_batch)  # (B,1,28,28)\n",
    "\n",
    "        # Euler update: X_{t+dt} = X_t + drift * dt\n",
    "        x = x + drift * dt\n",
    "\n",
    "    # After final step, x is an approximation of X_1 (data sample)\n",
    "    # Clamp values to [-1,1] for sanity (since training images were normalized)\n",
    "    x = torch.clamp(x, -1.0, 1.0)\n",
    "\n",
    "    # Return generated samples\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387f06b-9091-49c1-8eef-8827338944ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **8. Visualize Samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b63faca9-ff8f-4ef5-ad3f-523c402bb34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generated samples to samples/gsbflow_mnist_samples.png\n"
     ]
    }
   ],
   "source": [
    "# After training, sample generated images from the model\n",
    "samples = sample_from_model(model, num_samples=NUM_SAMPLES)\n",
    "\n",
    "# Optionally, save a grid of sampled images to disk for visualization\n",
    "os.makedirs(\"samples\", exist_ok=True)\n",
    "# Denormalize from [-1,1] back to [0,1] for saving as PNG\n",
    "samples_vis = (samples + 1.0) / 2.0\n",
    "# Use torchvision to save a grid image\n",
    "torchvision.utils.save_image(\n",
    "    samples_vis,\n",
    "    fp=\"samples/gsbflow_mnist_samples.png\",\n",
    "    nrow=int(math.sqrt(NUM_SAMPLES)),\n",
    ")\n",
    "print(\"Saved generated samples to samples/gsbflow_mnist_samples.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12e976-5d51-421f-a1c3-21c52dec91d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kaveh_gpu)",
   "language": "python",
   "name": "kaveh_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
